{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cede7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b20113",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('synthetic-meta.txt', sep=',', header=None)\n",
    "meta.columns = ['station', 'direction', 'date']\n",
    "z_meta = meta[meta.direction == 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(station):\n",
    "    df = pd.read_csv('../Artificial_data/DOGEx_v1/' + station, header=None)\n",
    "\n",
    "    df.columns = ['date', 'un', 'ue', 'uz', 'sn', 'se', 'sz']\n",
    "    df.drop(['sn', 'se', 'sz'], axis=1, inplace=True)\n",
    "    df = df[['date','uz']]\n",
    "\n",
    "    offset_dates = z_meta[z_meta.station==station.split('/')[1][0:4]]['date']\n",
    "    \n",
    "    return df, offset_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4083e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sliding window settings\n",
    "interval_size = 40\n",
    "offset = 10\n",
    "\n",
    "\n",
    "#run through each file in csv dir, \n",
    "#      calculate the total # of files, total # of windows, \n",
    "#      the name of each csv, and the windows per csv \n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../Artificial_data/DOGEx_v1/csv/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    \n",
    "    num_ranges = (sum(1 for line in open('../Artificial_data/DOGEx_v1/csv/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "    \n",
    "\n",
    "# create empty numpy array     \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "# run through each file and place each range into the ranges array\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv/'+csv_list[csv_idx])    \n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "\n",
    "    \n",
    "    \n",
    "# split ranges arr into X and y components, then train test split\n",
    "X = ranges[:, 1]\n",
    "y = ranges[:, 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# re-merge the X and y components (so we can then upsample)\n",
    "train = np.column_stack((X_train, y_train))\n",
    "test = np.column_stack((X_test, y_test))\n",
    "\n",
    "# upsample \n",
    "train_df = pd.DataFrame(train)\n",
    "train_df.columns = ['uz', 'label']\n",
    "regular = train_df[train_df.label == 0]\n",
    "offsets  = train_df[train_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "# split upsampled train data into X and y \n",
    "X_train = np.stack(np.array(data_upsampled['uz']))\n",
    "y_train = np.stack(np.array(data_upsampled['label']))\n",
    "\n",
    "\n",
    "# Perform the same upsampling process on the test set\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.columns = ['uz', 'label']\n",
    "regular = test_df[test_df.label == 0]\n",
    "offsets  = test_df[test_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled.label.value_counts()\n",
    "\n",
    "X_test = np.stack(np.array(data_upsampled['uz']))\n",
    "y_test = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89d644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sliding window dataset with a set of station data not used in the training set for testing\n",
    "\n",
    "interval_size = 40\n",
    "offset = 10\n",
    "\n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../Artificial_data/DOGEx_v1/csv_val/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    num_ranges = (sum(1 for line in open('../Artificial_data/DOGEx_v1/csv_val/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv_val/'+csv_list[csv_idx]) \n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "    \n",
    "data = pd.DataFrame(ranges)\n",
    "data.columns = ['dates', 'uz', 'label']\n",
    "regular = data[data.label == 0]\n",
    "offsets  = data[data.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled.label.value_counts()\n",
    "\n",
    "X_val = np.stack(np.array(data_upsampled['uz']))\n",
    "y_val = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a645169",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('sliced_data/X_train.csv', X_train, delimiter=\",\")\n",
    "np.savetxt('sliced_data/y_train.csv', y_train, delimiter=\",\")\n",
    "np.savetxt('sliced_data/X_test.csv', X_test, delimiter=\",\")\n",
    "np.savetxt('sliced_data/y_test.csv', y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3d231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('sliced_data/X_val.csv', X_val, delimiter=',')\n",
    "np.savetxt('sliced_data/y_val.csv', y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b0efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
