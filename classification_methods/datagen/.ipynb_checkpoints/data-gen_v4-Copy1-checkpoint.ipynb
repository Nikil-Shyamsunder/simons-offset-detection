{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cede7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5fc70",
   "metadata": {},
   "source": [
    "# Creating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b20113",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../../Artificial_data/DOGEx_v1/synthetic-meta.txt', sep=',', header=None)\n",
    "meta.columns = ['station', 'direction', 'date']\n",
    "e_meta = meta[meta.direction == 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(station):\n",
    "    df = pd.read_csv('../../Artificial_data/DOGEx_v1/' + station, header=None)\n",
    "\n",
    "    df.columns = ['date', 'un', 'ue', 'uz', 'sn', 'se', 'sz']\n",
    "    df.drop(['sn', 'se', 'sz'], axis=1, inplace=True)\n",
    "    df = df[['date','ue']]\n",
    "\n",
    "    offset_dates = e_meta[e_meta.station==station.split('/')[1][0:4]]['date']\n",
    "    \n",
    "    return df, offset_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4083e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sliding window settings\n",
    "interval_size = 100\n",
    "offset = 10\n",
    "\n",
    "\n",
    "#run through each file in csv dir, \n",
    "#      calculate the total # of files, total # of windows, \n",
    "#      the name of each csv, and the windows per csv \n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../../Artificial_data/DOGEx_v1/csv/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    \n",
    "    num_ranges = (sum(1 for line in open('../../Artificial_data/DOGEx_v1/csv/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "    \n",
    "\n",
    "# create empty numpy array     \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "# run through each file and place each range into the ranges array\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv/'+csv_list[csv_idx])  \n",
    "    df.set_index('date')\n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "\n",
    "    \n",
    "    \n",
    "# split ranges arr into X and y components, then train test split\n",
    "X = ranges[:, 1]\n",
    "y = ranges[:, 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# re-merge the X and y components (so we can then upsample)\n",
    "train = np.column_stack((X_train, y_train))\n",
    "test = np.column_stack((X_test, y_test))\n",
    "\n",
    "# upsample \n",
    "train_df = pd.DataFrame(train)\n",
    "train_df.columns = ['ue', 'label']\n",
    "regular = train_df[train_df.label == 0]\n",
    "offsets  = train_df[train_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "# split upsampled train data into X and y \n",
    "X_train = np.stack(np.array(data_upsampled['ue']))\n",
    "y_train = np.stack(np.array(data_upsampled['label']))\n",
    "\n",
    "\n",
    "# Perform the same upsampling process on the test set\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.columns = ['ue', 'label']\n",
    "regular = test_df[test_df.label == 0]\n",
    "offsets  = test_df[test_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled.label.value_counts()\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "X_test = np.stack(np.array(data_upsampled['ue']))\n",
    "y_test = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2388a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>[-0.04721647, -0.05259667, -0.05010058, -0.052...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8828</th>\n",
       "      <td>[0.51860788, 0.517851, 0.51942457, 0.51991983,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>[0.39250956, 0.39839678, 0.39634982, 0.3934890...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>[-0.18391101, -0.1894265, -0.1895975, -0.18907...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>[0.49872118, 0.5000422, 0.49684279, 0.49472051...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>[0.5013061, 0.47662414, 0.47965212, 0.47932337...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>[-0.14850462, -0.16145072, -0.15452356, -0.155...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>[0.02083008, 0.01567958, 0.01815026, 0.0120212...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>[0.33226844, 0.32860847, 0.33009824, 0.3277563...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>[0.22093405, 0.22079543, 0.22358739, 0.2181486...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18306 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ue label\n",
       "1833  [-0.04721647, -0.05259667, -0.05010058, -0.052...     0\n",
       "8828  [0.51860788, 0.517851, 0.51942457, 0.51991983,...     0\n",
       "2367  [0.39250956, 0.39839678, 0.39634982, 0.3934890...     0\n",
       "381   [-0.18391101, -0.1894265, -0.1895975, -0.18907...     0\n",
       "5279  [0.49872118, 0.5000422, 0.49684279, 0.49472051...     1\n",
       "...                                                 ...   ...\n",
       "8280  [0.5013061, 0.47662414, 0.47965212, 0.47932337...     1\n",
       "3732  [-0.14850462, -0.16145072, -0.15452356, -0.155...     1\n",
       "952   [0.02083008, 0.01567958, 0.01815026, 0.0120212...     0\n",
       "8413  [0.33226844, 0.32860847, 0.33009824, 0.3277563...     1\n",
       "8820  [0.22093405, 0.22079543, 0.22358739, 0.2181486...     0\n",
       "\n",
       "[18306 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89d644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sliding window dataset with a set of station data not used in the training set for testing\n",
    "\n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../../Artificial_data/DOGEx_v1/csv_val/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    num_ranges = (sum(1 for line in open('../../Artificial_data/DOGEx_v1/csv_val/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv_val/'+csv_list[csv_idx]) \n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "    \n",
    "data = pd.DataFrame(ranges)\n",
    "data.columns = ['dates', 'ue', 'label']\n",
    "regular = data[data.label == 0]\n",
    "offsets  = data[data.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "X_val = np.stack(np.array(data_upsampled['ue']))\n",
    "y_val = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a645169",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../sliced_data/window-100-step-10/ue/X_train.csv', X_train, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-10/ue/y_train.csv', y_train, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-10/ue/X_test.csv', X_test, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-10/ue/y_test.csv', y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3d231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../sliced_data/window-100-step-10/ue/X_val.csv', X_val, delimiter=',')\n",
    "np.savetxt('../sliced_data/window-100-step-10/ue/y_val.csv', y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce3996",
   "metadata": {},
   "source": [
    "# All directions combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c45307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train sets\n",
    "un = np.genfromtxt('../sliced_data/un/X_train.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/X_train.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/X_train.csv', delimiter=',')\n",
    "\n",
    "combined_X_train = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/X_train.csv', combined_X_train, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train sets\n",
    "un = np.genfromtxt('../sliced_data/un/y_train.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/y_train.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/y_train.csv', delimiter=',')\n",
    "\n",
    "combined_y_train = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/y_train.csv', combined_y_train, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16764713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test sets\n",
    "un = np.genfromtxt('../sliced_data/un/X_test.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/X_test.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/X_test.csv', delimiter=',')\n",
    "\n",
    "combined_X_test = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/X_test.csv', combined_X_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ddc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test sets\n",
    "un = np.genfromtxt('../sliced_data/un/y_test.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/y_test.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/y_test.csv', delimiter=',')\n",
    "\n",
    "combined_y_test = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/y_test.csv', combined_y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val sets\n",
    "un = np.genfromtxt('../sliced_data/un/X_val.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/X_val.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/X_val.csv', delimiter=',')\n",
    "\n",
    "combined_X_val = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/X_val.csv', combined_X_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val sets\n",
    "un = np.genfromtxt('../sliced_data/un/y_val.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/ue/y_val.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/uz/y_val.csv', delimiter=',')\n",
    "\n",
    "combined_y_val = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/combined/y_val.csv', combined_y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6bf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
