{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cede7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5fc70",
   "metadata": {},
   "source": [
    "# Creating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b20113",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../../Artificial_data/DOGEx_v1/synthetic-meta.txt', sep=',', header=None)\n",
    "meta.columns = ['station', 'direction', 'date']\n",
    "n_meta = meta[meta.direction == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(station):\n",
    "    df = pd.read_csv('../../Artificial_data/DOGEx_v1/' + station, header=None)\n",
    "\n",
    "    df.columns = ['date', 'un', 'ue', 'uz', 'sn', 'se', 'sz']\n",
    "    df.drop(['sn', 'se', 'sz'], axis=1, inplace=True)\n",
    "    df = df[['date','un']]\n",
    "\n",
    "    offset_dates =  n_meta[n_meta.station==station.split('/')[1][0:4]]['date']\n",
    "    \n",
    "    return df, offset_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sliding window settings\n",
    "interval_size = 100\n",
    "offset = 100\n",
    "\n",
    "\n",
    "#run through each file in csv dir, \n",
    "#      calculate the total # of files, total # of windows, \n",
    "#      the name of each csv, and the windows per csv \n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../../Artificial_data/DOGEx_v1/csv/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    \n",
    "    num_ranges = (sum(1 for line in open('../../Artificial_data/DOGEx_v1/csv/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "    \n",
    "\n",
    "# create empty numpy array     \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "# run through each file and place each range into the ranges array\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv/'+csv_list[csv_idx])    \n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "\n",
    "    \n",
    "    \n",
    "# split ranges arr into X and y components, then train test split\n",
    "X = ranges[:, 1]\n",
    "y = ranges[:, 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# re-merge the X and y components (so we can then upsample)\n",
    "train = np.column_stack((X_train, y_train))\n",
    "test = np.column_stack((X_test, y_test))\n",
    "\n",
    "# upsample \n",
    "train_df = pd.DataFrame(train)\n",
    "aregular = train_df[train_df.label == 0]\n",
    "offsets  = train_df[train_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "# split upsampled train data into X and y \n",
    "X_train = np.stack(np.array(data_upsampled['un']))\n",
    "y_train = np.stack(np.array(data_upsampled['label']))\n",
    "\n",
    "\n",
    "# Perform the same upsampling process on the test set\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.columns = ['un', 'label']\n",
    "regular = test_df[test_df.label == 0]\n",
    "offsets  = test_df[test_df.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled.label.value_counts()\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "X_test = np.stack(np.array(data_upsampled['un']))\n",
    "y_test = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sliding window dataset with a set of station data not used in the training set for testing\n",
    "\n",
    "num_files = 0\n",
    "tot_ranges = 0\n",
    "\n",
    "csv_list = []\n",
    "ranges_per_csv = []\n",
    "\n",
    "for file in os.listdir('../../Artificial_data/DOGEx_v1/csv_val/'):\n",
    "    if file[0] == '.':\n",
    "        continue \n",
    "    num_ranges = (sum(1 for line in open('../../Artificial_data/DOGEx_v1/csv_val/' + file)) - interval_size) // offset\n",
    "        \n",
    "    csv_list.append(file)\n",
    "    ranges_per_csv.append(num_ranges)\n",
    "    \n",
    "    tot_ranges += num_ranges\n",
    "    num_files +=  1\n",
    "    \n",
    "ranges = np.empty((tot_ranges, 3), dtype=np.ndarray)\n",
    "\n",
    "range_row = 0\n",
    "csv_idx = 0\n",
    "while range_row < tot_ranges:\n",
    "    df, offset_dates = process_csv('csv_val/'+csv_list[csv_idx]) \n",
    "    i = 0\n",
    "    while i < ranges_per_csv[csv_idx]:\n",
    "        arr = np.array(df.iloc[i * offset:i * offset + interval_size].T)\n",
    "\n",
    "        for date in arr[0]:\n",
    "            if date in offset_dates.values:\n",
    "                ranges[range_row] = (arr[0], arr[1], 1)\n",
    "                break\n",
    "            else:\n",
    "                ranges[range_row] = (arr[0], arr[1], 0)\n",
    "\n",
    "        i = i + 1  \n",
    "        range_row = range_row + 1   \n",
    "    \n",
    "    csv_idx += 1\n",
    "    \n",
    "data = pd.DataFrame(ranges)\n",
    "data.columns = ['dates', 'un', 'label']\n",
    "regular = data[data.label == 0]\n",
    "offsets  = data[data.label == 1]\n",
    "\n",
    "offsets_upsampled = resample(offsets, replace=True, n_samples=len(regular), random_state=42)\n",
    "data_upsampled = pd.concat([regular, offsets_upsampled])\n",
    "\n",
    "data_upsampled = data_upsampled.sample(frac=1)\n",
    "\n",
    "X_val = np.stack(np.array(data_upsampled['un']))\n",
    "y_val = np.stack(np.array(data_upsampled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a645169",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../sliced_data/window-100-step-100/un/X_train.csv', X_train, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-100/un/y_train.csv', y_train, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-100/un/X_test.csv', X_test, delimiter=\",\")\n",
    "np.savetxt('../sliced_data/window-100-step-100/un/y_test.csv', y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../sliced_data/window-100-step-100/un/X_val.csv', X_val, delimiter=',')\n",
    "np.savetxt('../sliced_data/window-100-step-100/un/y_val.csv', y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce3996",
   "metadata": {},
   "source": [
    "# All directions combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c45307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/X_train.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/X_train.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/X_train.csv', delimiter=',')\n",
    "\n",
    "combined_X_train = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/X_train.csv', combined_X_train, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/y_train.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/y_train.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/y_train.csv', delimiter=',')\n",
    "\n",
    "combined_y_train = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/y_train.csv', combined_y_train, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16764713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/X_test.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/X_test.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/X_test.csv', delimiter=',')\n",
    "\n",
    "combined_X_test = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/X_test.csv', combined_X_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ddc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/y_test.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/y_test.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/y_test.csv', delimiter=',')\n",
    "\n",
    "combined_y_test = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/y_test.csv', combined_y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/X_val.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/X_val.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/X_val.csv', delimiter=',')\n",
    "\n",
    "combined_X_val = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/X_val.csv', combined_X_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val sets\n",
    "un = np.genfromtxt('../sliced_data/window-200-step-10/un/y_val.csv', delimiter=',')\n",
    "ue = np.genfromtxt('../sliced_data/window-200-step-10/ue/y_val.csv', delimiter=',')\n",
    "uz = np.genfromtxt('../sliced_data/window-200-step-10/uz/y_val.csv', delimiter=',')\n",
    "\n",
    "combined_y_val = np.concatenate((un, ue, uz))\n",
    "\n",
    "np.savetxt('../sliced_data/window-200-step-10/combined/y_val.csv', combined_y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6bf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
